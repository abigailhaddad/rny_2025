---
title: "Processing Document Collections with LLMs: A Practical Workflow"
author: "Abigail Haddad"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    preview-links: auto
    transition: slide
    transition-speed: fast
    html-math-method: katex
    include-in-header: 
      - text: |
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
---

# Part 1: A Deadline {.section-header}

## 35,000 Public Comments to Analyze

![](images/hourglass.png){fig-align="left" width="200"}

**Deadline: [SOON]{.highlight}**

::: {.notes}
Building a tool to analyze public comments on Schedule F.
Need to know: do they support or oppose?
Comment period closing soon.
:::


---

## My Usual Blocks

![](images/my usual blocks.png){fig-align="center" width="600"}

::: {.notes}
I'd built document processing tools before. 
PyPDF2 for PDFs, python-docx for Word docs.
Simple, reliable blocks that worked great.
:::

---

## The Weird Stuff

::: {.columns}
::: {.column width="50%"}
::: {style="margin-top: 20%"}
**Dark scanned PDFs**

**Random meme attachments** 

**Blurry photos of handwritten notes**
:::
:::

::: {.column width="50%"}
![](images/meme.webp){fig-align="center"}
:::
:::

::: {.notes}
But this time, some attachments were weird.
My usual blocks were failing.
:::

---

## I Added a New Block

![](images/ocr.png){fig-align="center" width="700"}

::: {.notes}
So I added new blocks. OCR for images.
But that spit out gibberish sometimes.
:::

---

## I Occasionally Got Gibberish

![](images/is this text.png){fig-align="center" width="800"}

::: {.notes}
This is what I was staring at.
While the deadline approached.
:::

---

## So I Built a Gibberish Detector

![](images/gibberish detector blocks.png){fig-align="center" width="700"}

::: {.notes}
Now I'm debugging my gibberish detector...
:::

---

## Now I'm Debugging My Gibberish Detector

![](images/debugging.png){fig-align="center" width="700"}

::: {.notes}
The complexity was spiraling out of control.
:::

---

## Finally, I Try Gemini To Extract Text...

```python
if extraction_fails(doc):
    result = gemini.process(doc)
```

::: {.notes}
Finally said fuck it. Let me try Gemini on everything that fails.
It's multimodal, let's see how it does.
:::

---

## 

::: {style="text-align: center; font-size: 5em; margin-top: 20%; color: #f59e0b; font-weight: 800"}
It Works!! üéâüéäü•≥
:::

::: {.notes}
It just... worked. All of it. The dark PDFs, the memes, the handwritten notes.
Everything my complex pipeline couldn't handle.
:::

---

## Gemini Cost Me

![](images/seven cents.png){fig-align="center" width="600"}

::: {.notes}
Seven cents. That's what it cost.
:::

---

## The Result

‚úÖ **35,000 comments processed**

üöÄ **Website live in days**

‚è∞ **Avoided: months of manual work**

**Two blocks deleted:** [~~OCR~~]{style="color: red; text-decoration: line-through"}    [~~Gibberish Detector~~]{style="color: red; text-decoration: line-through"}

::: {.notes}
Seven cents. That's what it cost.
When those comments dropped, I was ready.
:::

---

## Here It Is

![](images/comment_site.jpg){fig-align="center" width="800"}

::: {.notes}
The final website showing all 35,000 comments analyzed and searchable.
:::

# Part 2: The Text Data Pipeline {.section-header}

## Every Organization Has These

üè• Stacks of medical records

üë§ Piles of resumes

üí¨ Endless customer complaints

‚ö†Ô∏è Streams of error logs

üìÑ Mountains of contracts

::: {.notes}
Every organization has document stacks.
Similar documents that need the same questions answered.
The time to process them blocks valuable insights.
:::

---

## Not RAG: Same Questions Each Time

**"Is this fraudulent?"**

**"Should we interview them?"**

**"What's the main complaint?"**

**"What caused the error?"**

**"What's the risk?"**

::: {.fragment style="margin-top: 2em"}
***Time Is The Barrier To Answering These***
:::

::: {.notes}
The same questions, asked about each document.
Currently done manually. Could be automated.
:::

---

## The Answer? Document Processing Pipeline

![](images/pipeline.png){fig-align="center" width="700"}


::: {.notes}
Every pipeline follows the same pattern.
Understanding this pattern is key.
:::

---

## The Three Steps

::: {.columns}
::: {.column width="40%"}
**GET**: Pull text from PDFs, Word docs, APIs, or user input

**PROCESS**: Use LLMs, regex, BERT, or other tools to extract meaning

**DO**: Create visualizations, populate templates, or trigger actions
:::

::: {.column width="60%"}
![](images/get process do blocks.png){fig-align="center"}
:::
:::

::: {.notes}
Every text processing pipeline follows this pattern.
Get text, process it, do something with results.
:::

# Part 3: How to Get Started {.section-header}


## Should I Throw It Into an LLM?

::: {.fragment style="font-size: 4em; color: #f59e0b; text-align: center; margin-top: 25%"}
**MAYBE!!!**
:::

::: {.notes}
It's not a yes or no question.
It depends on your specific constraints and requirements.
:::

---

## LLMs Work Well When...

::: {.incremental}
- [Accurate enough]{.emphasis} for your use case
- You have compute/budget for it
- Perfect legibility not required
- You control the model (or it's OK if it changes)
:::

::: {.notes}
LLMs aren't always the answer.
:::

---

## Alternative Tools

**Rule-based**

Examples: Regex, keyword matching, templates

Advantages: [Deterministic, fast, explainable]{.emphasis}

**Smaller models**  

Examples: BERT, language detection, translation

Advantages: [Run locally, less compute]{.emphasis}, predictable

[*Hybrid approaches can be the best*]{.highlight}

::: {.notes}
Don't default to LLMs. Sometimes simpler is better.
Often you want both - rules to catch the obvious, LLMs for the rest.
:::

# Part 4: Real World Lessons {.section-header}

## You Can't Build All The Blocks

![](images/too many blocks.png){fig-align="center" width="700"}

Each use case needs [different blocks]{.emphasis}

What works for one project [won't work for the next]{.emphasis}

::: {.notes}
The blocks you need are specific to your problem.
You'll always be building new ones.
:::

---

## My Specific Lessons

### As we scale up:

‚úì Handle failures gracefully

‚úì Parallelize operations  

‚úì Track state properly

‚úì Use real databases

::: {.notes}
What works for hundreds breaks at thousands.
:::

---

## When Working With Others

::: {.columns}
::: {.column width="50%"}
### Schemas become contracts:

üìã Schemas become [contracts]{.emphasis}

üîí Field names and formats [can't just change]{.emphasis}

‚úÖ Validation is [essential]{.emphasis}
:::

::: {.column width="50%"}
![](images/schema.png){fig-align="center"}
:::
:::

::: {.notes}
When someone else builds the frontend, your schema becomes a contract.
:::

---

## Questions to Ask?

::: {.columns}
::: {.column width="45%"}
::: {.fragment}
**Can data leave your environment?**
:::

::: {.fragment style="margin-top: 1.5em"}
**Need transparency?**
:::

::: {.fragment style="margin-top: 1.5em"}
**One-time or ongoing?**
:::

::: {.fragment style="margin-top: 1.5em"}
**How do you need it to fail?**
:::
:::

::: {.column width="55%"}
::: {.fragment}
‚Üí Local tools vs. cloud models
:::

::: {.fragment style="margin-top: 1.5em"}
‚Üí Explainable vs. black-box models
:::

::: {.fragment style="margin-top: 1.5em"}
‚Üí Monitoring needs for production systems
:::

::: {.fragment style="margin-top: 1.5em"}
‚Üí Silent failures vs. obvious failures
:::
:::
:::

::: {.notes}
These are the key questions that determine your architecture choices.
Each answer shapes what tools and approaches you can use.
:::

---

## Remember My Seven Cents?

**Gemini only worked because:**

::: {.incremental}
- ‚úì Data could leave my environment
- ‚úì 35,000 documents, most with no attachments = small enough for the budget
:::

::: {.fragment style="margin-top: 2em"}
[**Different constraints = Different solution**]{.emphasis}
:::

::: {.notes}
The seven-cent solution wasn't magic. It worked because my constraints allowed it.
Change any of those checkmarks to an X, and I'd need a totally different approach.
:::

---

# Part 5: Evaluation {.section-header}

## Evaluate Your Pipeline Systematically

- Create test cases early
- Include weird examples  
- Test edge cases
- Ask: ["What keeps me up at night?"]{.highlight}

::: {.notes}
From "What To Ask Your Engineers" - evaluation is critical.
Test on edge cases. Your weird data is someone's normal.
Work with your engineers to define success.
:::

---

## Make Iteration Painless

::: {.columns}
::: {.column width="50%"}
Build modularity into your processing layer:

- Swap models without changing code
- Test multiple prompts in parallel
- Compare results side-by-side
- Grid search across configurations

[**Modular design enables rapid experimentation**]{.highlight}
:::

::: {.column width="50%"}
![](images/make iteration painless.png){fig-align="center"}
:::
:::

::: {.notes}
Build your pipeline so you can easily test different models and prompts.
Abstract the LLM calls so you can iterate quickly.
:::

## Don't Forget Monitoring

**For production systems, you need a fourth step:**

::: {.incremental}
- **Natural labeling**: When you have ground truth later
- **Strategic sampling**: Human review of edge cases
- **Performance tracking**: Know when models drift
- **Failure alerts**: Catch problems early
:::

::: {.fragment style="margin-top: 2em"}
[**Production pipelines need ongoing care**]{.highlight}
:::

::: {.notes}
The fourth step that everyone forgets.
Especially important for LLMs that can fail silently.
:::

---

# Part 6: Conclusion {.section-header}

## Start Simple

![](images/get process do blocks.png){fig-align="center" width="600"}

**Build only the blocks you need**


::: {.notes}
Every pipeline follows the same pattern.
But each new surprise means more blocks.
Start simple. Add only what you need.
:::

---

## The Next Challenge

New comments. Different source.

[Another 7 months?]{.emphasis}

::: {.fragment style="margin-top: 2em"}
**No. I abstracted it.**

[Hours, not months.]{.highlight}
:::

::: {.notes}
The real power comes from abstraction.
Build once, reuse everywhere.
Time is no longer the barrier.
:::

---


---

## Questions?

::: {style="font-size: 1.2em; line-height: 2.5"}
üîó [github.com/abigailhaddad](https://github.com/abigailhaddad)

üìù [presentofcoding.substack.com](https://presentofcoding.substack.com)
:::

::: {.notes}
Remember: Start simple. Add blocks as needed.
Every organization has document stacks waiting to be processed.
:::